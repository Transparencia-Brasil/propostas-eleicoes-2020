---
title: "Relatório"
output:
  github_document:
    toc: true
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = T,
  comment = "#>",
  message = F,
  warning = F,
  echo = T,
  fig.align = "center"
)
```

## Leitura de dados

### Bibliotecas

```{r}
library(tidyverse)
library(here)
library(patchwork)
library(vegan) # NMDS
library(ggrepel)
library(tidytext) # topic modeling
library(topicmodels) # topic modeling
library(tm) # topic modeling
```

### Base de resultados das eleições

```{r}
# seleciona arquivos csv com resultados 1º e 2º turno
resultado_eleicao_csv_path <- here("load_data") %>% 
  list.files(pattern = "resultados", full.names = T)

# inspec
resultado_eleicao_csv_path %>% str_extract("resultados.+\\.csv")

# abre csv e combina os datasets em df único
resultado_eleicao <- resultado_eleicao_csv_path %>%
  purrr::map(data.table::fread) %>%
  purrr::reduce(bind_rows) %>%
  as_tibble()

# extrai somente candidatos eleitos
prefs_eleitos <- resultado_eleicao %>% filter(ds_situacao == "Eleito") %>% 
  mutate(sq_candidato = as.character(sq_candidato))

# inspec
glimpse(prefs_eleitos)
```

### Base das propostas eleitorais

```{r}
# carrega as propostas eleitorais
source(here("code/propostas0_candidaturas_validas.R"))
source(here("code/propostas2_aplica_buscador.R"))
# o source() traz objetos que não usa aqui:
rm("candidaturas_validas")
rm("deferidos_expost")
rm("dupl2")
rm("dupl3")

# inspec Global Environment
ls.str()
```

### Juntando prefeitos eleitos e propostas eleitorais

```{r}
# de-para: propostas + resultados eleições
depara_propostas_prefs_eleitos <- propostas %>% transmute(index, sq_candidato = as.character(id_divulga))

# junta as propostas e leitorais com a base de prefeitos eleitos
# full: inclui os candidatos eleitos sem proposta ou com texto de proposta não processado p/ análise
propostas_prefs_eleitos_full <- propostas2 %>% 
  left_join(depara_propostas_prefs_eleitos) %>%
  right_join(prefs_eleitos)

# inspec
glimpse(propostas_prefs_eleitos_full)
```

### Faz a contagem dos termos em cada proposta

```{r}
contagem_dos_termos <- function(df) {
  
  # set to test:
  # df <- propostas2
  # df <- propostas_prefs_eleitos_full
  
  # uma string com os termos para contar e fazer o pivot na base de propostas
  cols_to_pivot <- names(propostas2)[names(propostas2) != "texto_tidy"]

  # pega a base de propostas e realiza pivot com contagem de termos
  df <- df %>%
    select(all_of(cols_to_pivot)) %>%
    pivot_longer(-c(index:nm_urna_candidato), names_to = "termo", values_to = "qtd_mencoes") %>%
    group_by(termo) %>%
    summarise(qtd_mencoes = sum(qtd_mencoes, na.rm = T)) %>%
    ungroup() %>%
    mutate(
      
      # corrige os termos extraídos
      termo = termo %>%
        str_replace_all("_", " ") %>%
        str_to_sentence() %>%
        str_replace("cao", "ção") %>%
        str_replace("en", "ên") %>%
        fct_reorder(qtd_mencoes),
      # percentual de menções
      per = qtd_mencoes / sum(qtd_mencoes)
      
    )

  return(df)
  
}

# conta termos de todos os candidatos (eleitos + não-eleitos)
contagem_dos_termos(propostas2)

# conta termos só de quem foi eleito
contagem_dos_termos(propostas_prefs_eleitos_full)
```

#### Coloca a contagem em um gráfico

```{r}
contagem_dos_termos_plot <- function() {
  
  # legendas
  vec_base <- c(
    "O ponto em vermelho\né a frequência dos termos\nentre todos os candidatos",
    "Candidatos eleitos"
  )

  df <- list(
    
    propostas2,       # contagem de termos para todos os candidados 
    propostas_prefs_eleitos_full # contagem de termos só para eleitos
    
    ) %>%
    # aplica a função criada anteriormente
    map(contagem_dos_termos) %>%
    # wrap to df
    set_names(vec_base) %>%
    enframe(name = "base") %>%
    unnest(value)
  
  # plot
  df %>%
    ggplot(aes(x = termo, y = per)) +
    geom_col(data = . %>% filter(base == vec_base[2])) +
    geom_point(data = . %>% filter(base == vec_base[1]), aes(color = base)) +
    coord_flip() +
    scale_y_continuous(labels = scales::percent_format()) +
    labs(
      x = NULL,
      y = NULL,
      color = NULL
    ) +
    theme(legend.position = c(.7, .1))
}
```

#### Frequência relativa de menções de cada termo entre prefeitos eleitos

```{r}
# call plot
contagem_dos_termos_plot()
```


> Destaques:
>
> Candidaturas eleitas...
>
> -   utilizaram **mais** o termo transparência
>
> -   utilizaram **menos** o termo corrupção

</br>

### Faz a contagem dos termos em cada proposta e agrupa *por partido*

```{r}
contagem_dos_termos_por_partido <- function(df) {

  # set to test:
  # df <- propostas2
  # df <- propostas_prefs_eleitos_full

  cols_to_pivot <- names(propostas2)[names(propostas2) != "texto_tidy"]

  df <- df %>%
    select(all_of(cols_to_pivot)) %>%
    pivot_longer(transparencia:dados_abertos, values_to = "qtd", names_to = "termo") %>%
    mutate(
      termo = termo %>%
        str_replace_all("_", " ") %>%
        str_to_sentence() %>%
        str_replace("cao", "ção") %>%
        str_replace("en", "ên")
    ) %>%
    group_by(termo, sg_partido) %>%
    summarise(
      qt_termo_partido = sum(qtd, na.rm = T),
      qt_candidatura = n(),
      freq_termo = qt_termo_partido / qt_candidatura
    ) %>%
    ungroup() %>%
    mutate(
      grau = case_when(
        freq_termo < 0.2 ~ "até 1 em cada 5 propostas citam o termo",
        freq_termo < 1.0 ~ "pelo menos 1 em cada 2 propostas citam o termo",
        TRUE ~ "Todas as propostas citam o termo ao menos 1 vez"
      ) %>%
        factor(
          levels = c(
            "até 1 em cada 5 propostas citam o termo",
            "pelo menos 1 em cada 2 propostas citam o termo",
            "Todas as propostas citam o termo ao menos 1 vez"
          )
        )
    )

  return(df)
}

glimpse(contagem_dos_termos_por_partido(propostas2))
glimpse(contagem_dos_termos_por_partido(propostas_prefs_eleitos_full))
```

#### Coloca a contagem em um gráfico

```{r}
contagem_dos_termos_por_partido_plot <- function(df, token) {

  # set to test:
  # df <- propostas2
  # df <- propostas_eleitas
  # token <- "Transparência"

  contagem_dos_termos_por_partido(df) %>%
    filter(termo == token) %>%
    mutate(
      sg_partido = fct_reorder(sg_partido, freq_termo),
      termo = fct_reorder(termo, freq_termo)
    ) %>%
    ggplot(aes(x = sg_partido, y = freq_termo, fill = grau)) +
    geom_vline(aes(xintercept = sg_partido), lty = 2, color = "gray60") +
    geom_point(shape = 21, size = 6, alpha = .5) +
    scale_fill_manual(values = c("#FC4E07", "#E7B800", "#00AFBB"), drop = FALSE) +
    facet_wrap(~termo, scales = "free_x") +
    labs(
      x = NULL,
      y = NULL,
      fill = NULL
    ) +
    coord_flip() +
    theme_bw() +
    theme(
      plot.title = element_text(hjust = .5, vjust = .5, size = 18),
      legend.text = element_text(size = 13),
      axis.text = element_text(size = 12, face = "bold"),
      strip.text = element_text(size = 12, face = "bold"),
      strip.background = element_blank()
    ) +
    guides(fill = guide_legend(ncol = 1))
  
}
```

Monta o grid de gráficos

```{r}
termo <- contagem_dos_termos_por_partido(propostas_prefs_eleitos_full) %>%
  distinct(termo) %>%
  pull()

termo 

# test
# plot_freq_termos(propostas_prefs_eleitos_full, termo[1])

# junta os gráficos com patchwork
p1 <- map(termo[1:2], ~ contagem_dos_termos_por_partido_plot(propostas_prefs_eleitos_full, .x)) %>%
  reduce(~ `+`(.x, .y)) +
  plot_layout(guides = "collect") &
  theme(legend.position = "top")

p2 <- map(termo[3:4], ~ contagem_dos_termos_por_partido_plot(propostas_prefs_eleitos_full, .x)) %>%
  reduce(~ `+`(.x, .y)) &
  theme(legend.position = "none")

p3 <- p1 / p2 & theme(plot.title = element_text(hjust = .5, vjust = .5, size = 18, face = "bold"))

p4 <- map(termo[5:6], ~ contagem_dos_termos_por_partido_plot(propostas_prefs_eleitos_full, .x)) %>%
  reduce(~ `+`(.x, .y)) +
  plot_layout(guides = "collect") &
  theme(legend.position = "top")

p5 <- map(termo[7], ~ contagem_dos_termos_por_partido_plot(propostas_prefs_eleitos_full, .x)) %>%
  reduce(~ `+`(.x, .y)) &
  theme(legend.position = "none")

p6 <- (p4 + p5) +
  plot_layout(nrow = 2) +
  theme(plot.title = element_text(hjust = .5, vjust = .5, size = 18, face = "bold"))
# p3
```

#### Frequência relativa de menções de cada termo entre prefeitos eleitos

```{r echo = FALSE, fig.height=15, fig.width=10}
p3
```

```{r echo = FALSE, fig.height=15, fig.width=10}
p6
```

## Análise NMDS

<details>
  <summary>
  <b>Clique para ver código completo</b>
  </summary>

```{r}
colunas <- c(
  
  "transparencia",
  "corrupcao",
  "integridade",
  "governo_aberto",
  "acesso_a_informacao",
  "controle_social",
  "dados_abertos"
  
)


# define a semente para reproduzir resultado
# escolhe um valor aleatoreamente
# s <- sample(1:999, 1)
# s = 120 ajustou bem
set.seed(10)

# PARTIDOS =====================================================================
{
  # . Matriz input -------------------------------------------------------------
  partidos <- propostas_prefs_eleitos_full %>%
    select(-index) %>%
    mutate(across(all_of(colunas), ~ ifelse(. == 0, ., 1))) %>%
    group_by(sg_partido) %>%
    summarise(
      qt_candidaturas = n(),
      across(where(is.double), ~ sum(., na.rm = T))
    ) %>%
    ungroup() %>%
    rowwise() %>%
    mutate(sumVar = sum(c_across(all_of(colunas)))) %>%
    mutate(across(all_of(colunas), ~ (. / qt_candidaturas))) %>%
    select(-c(qt_candidaturas, sumVar)) %>%
    column_to_rownames("sg_partido") %>%
    t()

  # inspec
  as_tibble(partidos)

  # . nmds ---------------------------------------------------------------------
  nmds_partido <- metaMDS(decostand(partidos, "hellinger"),
    distance = "euclidean",
    k = 4,
    trymax = 10
  )
  # fit
  nmds_partido
  nmds_partido$stress
  stressplot(nmds_partido, main = "Diagrama de Shepard")

  # . tidy nmds data -----------------------------------------------------------
  # Using the scores function from vegan to extract the site scores and convert to a data.frame
  site_scores_partido <- as.data.frame(scores(nmds_partido, "site"))
  site_scores_partido <- site_scores_partido %>%
    mutate(
      site = rownames(site_scores_partido),
      site = str_replace_all(site, "_", " ") %>%
        str_to_sentence() %>%
        str_replace("cao", "ção") %>%
        str_replace("en", "ên")
    )

  # Using the scores function from vegan to extract the species scores and convert to a data.frame
  species_scores_partido <- as.data.frame(scores(nmds_partido, "species"))
  species_scores_partido <- species_scores_partido %>% mutate(species = rownames(species_scores_partido))
} # Processa matriz para partidos

# CANDIDATOS ===================================================================
{
  # . Matriz input -------------------------------------------------------------
  candidatos <- propostas_prefs_eleitos_full %>%
    # soma na linha
    rowwise() %>%
    mutate(sumVar = sum(c_across(all_of(colunas)))) %>%
    filter(sumVar > 0) %>%
    group_by(sg_partido) %>%
    mutate(qt_candidaturas_partido = n()) %>%
    ungroup() %>%
    mutate(across(all_of(colunas), ~ (. / qt_candidaturas_partido) * sumVar),
      index = paste0(sg_partido, index)
    ) %>%
    select(c("index", colunas)) %>%
    column_to_rownames("index") %>%
    t()

  # inspec
  as_tibble(candidatos)

  # . nmds ---------------------------------------------------------------------
  nmds_candidato <- metaMDS(decostand(candidatos, "hellinger"),
    distance = "euclidean",
    k = 4,
    trymax = 10
  )

  nmds_candidato
  nmds_candidato$stress
  stressplot(nmds_candidato, main = "Diagrama de Shepard")

  # . tidy nmds data -----------------------------------------------------------
  # Using the scores function from vegan to extract the site scores and convert to a data.frame
  site_scores_candidato <- as.data.frame(scores(nmds_candidato, "site"))
  site_scores_candidato <- site_scores_candidato %>%
    mutate(
      site = rownames(site_scores_candidato),
      site = str_replace_all(site, "_", " ") %>%
        str_to_sentence() %>%
        str_replace("cao", "ção") %>%
        str_replace("en", "ên")
    )
  site_scores_candidato

  # Using the scores function from vegan to extract the species scores and convert to a data.frame
  species_scores_candidato <- as.data.frame(scores(nmds_candidato, "species"))
  species_scores_candidato <- species_scores_candidato %>%
    mutate(species = rownames(species_scores_candidato))


  species_scores_candidato <- species_scores_candidato %>%
    as_tibble() %>%
    mutate(partido = gsub("(^\\D+)(\\d+$)", "\\1", species))
} # Processa NMDS para cada candidato

# VISUALIZAÇÂO =================================================================

{
  candidatos_grp <- species_scores_candidato %>%
    left_join(

      # quantidade de candidaturas iguais (nas repetições de termos):
      propostas2 %>%
        mutate(species = paste0(sg_partido, index)) %>%
        group_by(
          transparencia,
          corrupcao,
          integridade,
          governo_aberto,
          acesso_a_informacao,
          controle_social,
          dados_abertos
        ) %>%
        mutate(qt_candidaturas = n()) %>%
        ungroup() %>%
        arrange(desc(qt_candidaturas)) %>%
        select(species, qt_candidaturas)
    ) %>%
    filter(!is.nan(NMDS1)) %>%
    distinct(qt_candidaturas, NMDS1, NMDS2, NMDS3, NMDS4, .keep_all = T) %>%
    mutate(
      fx = case_when(
        qt_candidaturas < 5 ~ "1 a 5",
        qt_candidaturas < 11 ~ "1 a 10",
        qt_candidaturas < 31 ~ "11 a 30",
        qt_candidaturas < 61 ~ "31 a 60",
        qt_candidaturas < 101 ~ "61 a 100",
        TRUE ~ "> 100"
      )
    )

  plot_nmds <- function(dim1, dim2) {
    d1 <- enquo(dim1)
    d2 <- enquo(dim2)

    # labs
    x_lbl <- rlang::as_name(d1) %>% str_extract("\\d")
    y_lbl <- rlang::as_name(d2) %>% str_extract("\\d")
    size_lbl <- c("1 a 5", "6 a 10", "11 a 30", "31 a 60", "61 a 100", ">100")

    ggplot() +
      geom_jitter(
        data = candidatos_grp,
        aes(
          x = !!d1,
          y = !!d2,
          size = qt_candidaturas
        ),
        alpha = .1,
        shape = 21,
        fill = "seashell",
        color = "black",
        # stroke = 3,
        # show.legend = F,
        width = 0.02,
        height = 0.02
      ) +
      geom_text(
        data = site_scores_candidato,
        aes(
          x = !!d1,
          y = !!d2,
          label = site
        ),
        alpha = .8,
        fontface = "bold",
        size = 4.5
      ) +
      geom_text_repel(
        data = species_scores_partido,
        aes(
          x = !!d1,
          y = !!d2,
          label = species,
          color = cluster
        ),
        color = "red",
        size = 3.5,
        show.legend = F
      ) +
      geom_point(
        data = species_scores_partido,
        aes(
          x = !!d1,
          y = !!d2
        ),
        color = "firebrick",
        size = 2,
        show.legend = F
      ) +
      theme_minimal() +
      scale_size_continuous(
        range = c(2, 30),
        breaks = c(5, 10, 30, 60, 100, 500),
        labels = size_lbl,
        limits = c(0, 2500)
      ) +
      labs(
        title = "Análise NMDS:\nsimilaridade de partidos em torno do tema \"transparência\"",
        size = "Quantidade de\ncandidaturas\nna posição:",
        x = paste("Dimensão", x_lbl),
        y = paste("Dimensão", y_lbl),
        # subtitle = paste("SEED:", s),
        caption = "stress-value=0"
      ) +
      theme(
        plot.title = element_text(hjust = .5, vjust = .5, size = 18),
        axis.title = element_text(size = 10),
        axis.text = element_blank(),
        panel.grid = element_blank(),
        panel.border = element_rect(fill = "transparent"),
        legend.title = element_text(hjust = .5, vjust = .5, size = 12),
        legend.text = element_text(size = 12),
        plot.caption = element_text(size = 8, face = "italic")
      )
  }
} # Processa visualização
```

</details>

```{r}
# Explora eixos
plot_nmds(dim1 = NMDS1, dim2 = NMDS2)
plot_nmds(dim1 = NMDS1, dim2 = NMDS3)
plot_nmds(dim1 = NMDS1, dim2 = NMDS4)

plot_nmds(dim1 = NMDS2, dim2 = NMDS3)
plot_nmds(dim1 = NMDS2, dim2 = NMDS4)
#
plot_nmds(dim1 = NMDS3, dim2 = NMDS4)
```

## Topic Modeling

### Processamento de texto

```{r}
propostas_prefs_eleitos <- propostas_prefs_eleitos_full %>% 
  filter(!is.na(texto_tidy)) %>%
  mutate(
    
   # realiza mais alguns tratamentos para tokenização
    texto_tidy = str_replace_all(texto_tidy, "[[:punct:]]", " ") %>% str_squish(),
    texto_tidy = str_remove_all(texto_tidy, "[[:punct:]]"),
    texto_tidy = stringi::stri_trans_general(texto_tidy, "Latin-ASCII"),
    texto_tidy = iconv(texto_tidy, to = "ASCII//TRANSLIT"),
    texto_tidy = str_replace_all(texto_tidy, "pc do b", "pcdob")
  
  )
```

### Stopwords

```{r}
# . stopwords função -----------------------------------------------------------
df_stopwords_fun <- get_stopwords("pt") %>% 
  mutate(word = stringi::stri_trans_general(word, "Latin-ASCII"),
         word = iconv(word, to = "ASCII//TRANSLIT"))

# . stopwords custom -----------------------------------------------------------
df_stopwords_custom <- tibble(
  word = c("azc", "az", "io", "fim", "esf", "ano", "pra", "ser", "ars", "cid",
           "yi", "demais", "if", "aa", "pag"),
  lexicon = "Custom"
)

df_stopwords_extra <- tibble(
  word = c("municipio", "municipal", "cidade"),
  lexicon = "Extra"
)

# . stopwords partidos ---------------------------------------------------------
df_stopwords_partidos <- propostas_prefs_eleitos %>% 
  distinct(sg_partido) %>% 
  transmute(
    word = sg_partido %>% 
      tolower() %>% 
      iconv(., to = "ASCII//TRANSLIT"),
    lexicon = "Partidos"
  )

# . junta stopwords ------------------------------------------------------------
df_stopwords <- bind_rows(
  
  df_stopwords_fun,
  df_stopwords_custom,
  #df_stopwords_partidos,
  df_stopwords_extra
  
)
```

### Tokenização

```{r}
# . unnest_tokens --------------------------------------------------------------
df_words <- propostas_prefs_eleitos %>% 
  select(sq_candidato, texto_tidy, sg_partido) %>% #sample_frac(.4) %>%  
  # . . remove stopwords ---------------
  unnest_tokens(word, texto_tidy) %>%
  mutate(
    
    word = word %>% 
      str_remove_all("\\d") %>%
      gsub("^(a)(a.+)$", "\\2", .) %>% 
      gsub("([^rs])\\1+", "\\1", .) %>% 
      gsub("^ss+|ss+$", "s", .) %>% 
      gsub("^rr+|rr+$", "r", .)
    
  ) %>% 
  filter(!str_detect(word, "^[[:alpha:]]$")) %>%
  filter(!str_detect(word, "^$")) %>% 
  anti_join(df_stopwords)
```

#### Processamentos adicionais após a tokenização

```{r}
# . . remove textos muito sujo ---------
# alguns pdf estão ruins, texto sem espaço
textos_muito_sujos <- df_words %>% mutate(e = str_count(word)) %>%
  arrange(desc(e)) %>% 
  filter(e > 21) %>%
  #filter(sq_candidato == "50001028167") %>% 
  count(sq_candidato, sort = T) %>% 
  filter(n > 8) %>% 
  pull(sq_candidato)

#helper
`%notin%` <- function(x, y) !(x %in% y)

# . . remove palavras muito grande ------
df_words <- df_words %>%
  filter(sq_candidato %notin% textos_muito_sujos) %>% 
  filter(str_count(word) < 21) %>% 
  group_by(word) %>% 
  filter(n() > 1) %>% ungroup()
```

### Distribuição de frequência das palavras

```{r}
# . candidato ------------------------------------------------------------------
# contagem_prefs <- df_words %>% count(sq_candidato, word, sort = T)
# 
# contagem_prefs <- contagem_prefs %>% 
#   left_join(propostas_prefs_eleitos %>% select(sq_candidato, sg_partido))
```

### Top 30 palavras mais usadas

```{r fig.height=6, fig.width=4}
df_words_rnkg <- df_words %>% 
  count(word, sort = T) %>% 
  mutate(rank = row_number())

(df_words_rnkg_transparencia <- df_words_rnkg %>% filter(word == "transparencia"))

df_words_rnkg %>% filter(rank < 31) %>% 
  bind_rows(df_words_rnkg_transparencia) %>%
  ggplot(aes(x = fct_reorder(word, n), y = n)) + 
  geom_col() +
  coord_flip() +
  labs(x = NULL, y = "Quantidade")
```

### Topic modeling

```{r}
my_topic_model <- function(df, id, partido) {
  
  id <- enquo(id)
  
  # cria uma document term matrix (matriz esparsa, necessária pra rodar o LDA)
  propostas_dtm <- df %>% cast_dtm(document = !!id, word, n)
  
  # roda LDA. No meu pc deu quase 10min
  propostas_lda <- LDA(propostas_dtm, k = 5, control = list(seed = 420))
  
  # extrai os topicos
  propostas_topics <- tidy(propostas_lda, matrix = "beta")
  
  # pega as 10 palavras mais associadas a cada tópico
  top_terms <- propostas_topics %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    ungroup() %>%
    arrange(topic, -beta)
  
  # gráfico com os top terms
  plot <- top_terms %>%
    mutate(term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free") +
    coord_flip() +
    scale_x_reordered() + labs(title = glue::glue("{partido}"))
  
  return(list(
    
    propostas_dtm = propostas_dtm,
    propostas_lda = propostas_lda,
    propostas_topics = propostas_topics,
    top_terms = top_terms,
    plot = plot
    
  ))
  
}

# teste
# my_topic_model(df = df_words %>% filter(sg_partido == partidos[1]) %>% count(sq_candidato, word),
#                id = sq_candidato,
#                partido = partidos[1])

topic_model_partido <- function(partido) {
  
  message(glue::glue("\nProcessando propostas do partido: {partido}\n"))
  
  l <- df_words %>%
    filter(sg_partido == partido) %>% 
    count(sq_candidato, word, sort = TRUE) %>% 
    my_topic_model(df = ., id = sq_candidato, partido = partido)

  return(l)
  
}
```


```{r}
(partidos <- df_words %>% distinct(sg_partido) %>% pull())

map(partidos, topic_model_partido) %>% set_names(partidos)
```

